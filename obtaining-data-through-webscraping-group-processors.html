<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="MFIN7036 Students" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Progress Report, " />

<meta property="og:title" content="Obtaining Data through Webscraping (Group Processors) "/>
<meta property="og:url" content="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/obtaining-data-through-webscraping-group-processors.html" />
<meta property="og:description" content="By Group &#34;Processors&#34; Text Sources The first step of our project is to obtain bitcoin and cryptocurrency related text data. We mainly focus on two types of text data - social media and news articles. For social media, we make use of the following sources: Conversation under BTC-USD at Yahoo Finance …" />
<meta property="og:site_name" content="MFIN7036 Student Blog" />
<meta property="og:article:author" content="MFIN7036 Students" />
<meta property="og:article:published_time" content="2022-03-21T12:25:00+08:00" />
<meta name="twitter:title" content="Obtaining Data through Webscraping (Group Processors) ">
<meta name="twitter:description" content="By Group &#34;Processors&#34; Text Sources The first step of our project is to obtain bitcoin and cryptocurrency related text data. We mainly focus on two types of text data - social media and news articles. For social media, we make use of the following sources: Conversation under BTC-USD at Yahoo Finance …">

        <title>Obtaining Data through Webscraping (Group Processors)  · MFIN7036 Student Blog
</title>
        <link href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="MFIN7036 Student Blog - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/"><span class=site-name>MFIN7036 Student Blog</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/MFIN7036-student-blog-2022-02
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/obtaining-data-through-webscraping-group-processors.html">
                Obtaining Data through Webscraping (Group Processors)
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By Group "Processors"</p>
<h1>Text Sources</h1>
<p>The first step of our project is to obtain bitcoin and cryptocurrency related text data. We mainly focus on two types of text data - social media and news articles. For social media, we make use of the following sources:</p>
<ol>
<li><a href="https://finance.yahoo.com/quote/BTC-USD/community/">Conversation under BTC-USD at Yahoo Finance</a></li>
<li><a href="https://www.reddit.com/">Reddit</a></li>
<li><a href="https://bitcointalk.org/">Bitcointalk</a></li>
<li><a href="https://twitter.com/?lang=en">Twitter</a></li>
</ol>
<p>While for news article, we obtain from the following sources:</p>
<ol>
<li><a href="https://cryptonews.com/">Crypto News</a></li>
<li><a href="https://finance.yahoo.com/topic/crypto/">Cryptocurrency News at Yahoo Finance</a></li>
</ol>
<h1>Price data Sources</h1>
<p>The price data related bitcoin price we obtain from the below website:</p>
<ol>
<li><a href="https://coinmarketcap.com/currencies/bitcoin/historical-data/">CoinMarketcap</a></li>
</ol>
<h1>Tool</h1>
<p>To extra data from the above mentioned website, we utilize web scaping with the tool of <code>WebDriver</code> from the <code>Selenium</code> library along with a little bit of <code>BeautifulSoup</code>.</p>
<h1>Web Scraping</h1>
<h3>Conversation under BTC-USD at Yahoo Finance</h3>
<p>The default way to display the comments on this website is by popularity, but because we want to obtain all comments within a certain timeframe, we have to first change the display method to by publish time.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># display discussion by reaction time from the most recent to the least</span>
<span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;canvass-0-CanvassApplet&quot;]/div/div[3]/button&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
<span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;canvass-0-CanvassApplet&quot;]/div/div[3]/ul/li[2]/button&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
</code></pre></div>

<p>The initial page only shows 20 comments. To access more comments, we need to click the 'Show more' button to load 20 extra each time. We decide to load all the comments within the desired timeframe on the website before scrapping them. We are not able to come up with a smart way to have the computer to stop itself automatically when it reaches a specific date so we just go with the stupid one instead. The stupid way is to write a loop to click the button 300 times, then we manually check the date of the last comment. If it has not gotten to the desired date, we would have the button clicked for another 300 times. This process would be repeated until we have all the data we wanted. </p>
<div class="highlight"><pre><span></span><code><span class="c1"># click the &quot;Load more&quot; button for 300 times</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">300</span><span class="p">):</span> 
    <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;canvass-0-CanvassApplet&quot;]/div/button&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span> <span class="c1"># add random time sleep to avoid being detected by the website</span>

<span class="c1"># after the certain clicks, the xpath of the button changes, we then have to use the updated xpath</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span> 
    <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;canvass-0-CanvassApplet&quot;]/div/button[2]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>  
</code></pre></div>

<p>After finish loading all the comments, we scrap the content, date, and author of these comments and save them into a dataframe.</p>
<div class="highlight"><pre><span></span><code><span class="n">Author</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;canvass-0-CanvassApplet&quot;]/div/ul/li[position()&gt;=1]/div/div[1]/button&#39;</span><span class="p">)</span>                                                                         
<span class="n">Author</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">Author</span><span class="p">))</span>

<span class="n">Con</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;canvass-0-CanvassApplet&quot;]/div/ul/li[position()&gt;=1]/div/div[2]&#39;</span><span class="p">)</span>
<span class="n">Con</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">Con</span><span class="p">))</span>

<span class="n">Time</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;canvass-0-CanvassApplet&quot;]/div/ul/li[position()&gt;=1]/div/div[1]/span/span&#39;</span><span class="p">)</span>                                                                                               
<span class="n">Time</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">Time</span><span class="p">))</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;author&#39;</span><span class="p">:</span> <span class="n">Author</span><span class="p">,</span> <span class="s1">&#39;date&#39;</span><span class="p">:</span> <span class="n">Time</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">Con</span><span class="p">})</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;last month&#39;</span><span class="p">)]</span> <span class="c1"># we only want the comments from the past 30 days and we don&#39;t want comments only contain picture without any text.</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p>Only the comments posted in less than 24 hours would have an exact time and all others only have the date as 'x day ago', but since we would like to keep the format of the date organized, we change all the date into the 'x day ago' format.</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])):</span>
    <span class="k">if</span> <span class="s1">&#39;hour&#39;</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]:</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0 day ago&#39;</span>
    <span class="k">elif</span> <span class="s1">&#39;minutes&#39;</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]:</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;0 day ago&#39;</span>
    <span class="k">elif</span> <span class="s1">&#39;yesterday&#39;</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]:</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;1 day ago&#39;</span>
</code></pre></div>

<p>After changed all the date into the 'x days ago' format, I changed all the date into '%Y-%m-%d' format in order to match the date format in to price data.</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">])):</span>
    <span class="n">days_age</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span> <span class="o">-</span> <span class="n">timedelta</span><span class="p">(</span><span class="n">days_age</span><span class="p">))</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1">&#39;</span><span class="p">)</span>
</code></pre></div>

<h3>Reddit</h3>
<p>Redidt is an American social news aggregation, but unlike normal news sites he will stream a comment section under each news item for people to discuss freely. Thus, we scarpe comments to learn people's attitude towards latest news.</p>
<p>At the beginning of the data crawl, we chose to search for relevant posts using bitcoin as a keyword. Then, recording all the headlines and comments of the searched result. However, while browsing through the text results, we noticed that some news headlines and comments were not protected by the keywords in all the results. This made us suspicious of the crawl results. </p>
<p>Later, after searching, we found that most of the keywords searched were contained in the content of the news content, not the headline. Besides, many news contents are more important than the headlines. </p>
<p>However, because the news content is too long, adding them to the original comments storage file always reports an error indicating that the length is exceeded. Therefore, we rewrote the code and decided to generate two txt files. We wrote two functions that generate text documents, and one of them holds the news contents and the other holds the title and each comment.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">save_comments_data</span><span class="p">(</span><span class="n">keyword</span><span class="p">,</span> <span class="n">post</span><span class="p">,</span> <span class="n">comment_list</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/&quot;</span> <span class="o">+</span> <span class="n">keyword</span> <span class="o">+</span> <span class="s2">&quot;.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">comment</span> <span class="ow">in</span> <span class="n">comment_list</span><span class="p">:</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">post</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">comment</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">save_contents_data</span><span class="p">(</span><span class="n">keyword</span><span class="p">,</span> <span class="n">txt_list</span><span class="p">,</span> <span class="n">contents_list</span><span class="p">,</span> <span class="n">time_list</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;data/&quot;</span> <span class="o">+</span> <span class="n">keyword</span> <span class="o">+</span> <span class="s2">&quot;_contents.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">txt_list</span><span class="p">)):</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">txt_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">contents_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">time_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Since the site could not load all relevant news on the same page, we needed to keep clicking the go to next page button to make sure the program could navigate to all relevant news.</p>
<div class="highlight"><pre><span></span><code><span class="n">res_urls</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s1">&#39;span&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s2">&quot;nextprev&quot;</span><span class="p">))</span>
</code></pre></div>

<p>After that, we also need to add new parameters in order to get the time of each news release and find them all the time by looping through the implementation. We get the web address, the exact time, and the related content of each news item through a self-defined function.</p>
<p>Among other things, we initially had some difficulty in getting a specific time. This is because, when browsing the web, we find that the web page only shows how many days ago the news was published, and there is no way to get the exact time of publication of each article. When querying its html code, the exact time when this news was published is known after the datetime indicator.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">getPageData</span><span class="p">(</span><span class="n">browser</span><span class="p">,</span> <span class="n">search_url</span><span class="p">):</span>
    <span class="n">txt_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">url_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">time_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">js</span> <span class="o">=</span> <span class="s2">&quot;window.open(</span><span class="se">\&quot;</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">search_url</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\&quot;</span><span class="s2">)&quot;</span>

    <span class="c1"># open link in a new browser window</span>
    <span class="n">browser</span><span class="o">.</span><span class="n">execute_script</span><span class="p">(</span><span class="n">js</span><span class="p">)</span>  
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># move the handle to operate on the newly opened page</span>
    <span class="n">browser</span><span class="o">.</span><span class="n">switch_to</span><span class="o">.</span><span class="n">window</span><span class="p">(</span><span class="n">browser</span><span class="o">.</span><span class="n">window_handles</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>  
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">browser</span><span class="o">.</span><span class="n">page_source</span><span class="p">,</span> <span class="s2">&quot;lxml&quot;</span><span class="p">)</span>
    <span class="n">res_contents</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s1">&#39;div&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s2">&quot;listing search-result-listing&quot;</span><span class="p">))</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">res_contents</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">res_content</span> <span class="o">=</span> <span class="n">res_contents</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">res_times</span> <span class="o">=</span> <span class="n">res_content</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s1">&#39;time&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">res_time</span> <span class="ow">in</span> <span class="n">res_times</span><span class="p">:</span>
            <span class="n">time_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">res_time</span><span class="p">[</span><span class="s1">&#39;datetime&#39;</span><span class="p">])</span>

        <span class="n">res_posts</span> <span class="o">=</span> <span class="n">res_content</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s2">&quot;search-title may-blank&quot;</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">post</span> <span class="ow">in</span> <span class="n">res_posts</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">post</span><span class="o">.</span><span class="n">strings</span><span class="p">))</span>
            <span class="n">url_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">post</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">])</span>
            <span class="n">txt_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">txt_list</span><span class="p">),</span> <span class="n">txt_list</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">url_list</span><span class="p">),</span> <span class="n">url_list</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">time_list</span><span class="p">),</span> <span class="n">time_list</span><span class="p">)</span>
        <span class="n">res_urls</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s1">&#39;span&#39;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s2">&quot;nextprev&quot;</span><span class="p">))</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">res_urls</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">res_url</span> <span class="o">=</span> <span class="n">res_urls</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s1">&#39;a&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">res_url</span><span class="o">.</span><span class="n">string</span> <span class="o">==</span> <span class="s2">&quot;下一頁 ›&quot;</span><span class="p">:</span>

                <span class="k">return</span> <span class="n">txt_list</span><span class="p">,</span> <span class="n">url_list</span><span class="p">,</span> <span class="n">time_list</span><span class="p">,</span> <span class="n">res_url</span><span class="p">[</span><span class="s1">&#39;href&#39;</span><span class="p">]</span>

        <span class="c1"># adjust the scroll bar to the bottom of the web page</span>
        <span class="n">scroll_to_bottom</span><span class="p">(</span><span class="n">browser</span><span class="p">)</span>  
        <span class="k">return</span> <span class="n">txt_list</span><span class="p">,</span> <span class="n">url_list</span><span class="p">,</span> <span class="n">time_list</span><span class="p">,</span> <span class="kc">None</span>
</code></pre></div>

<p>After that, we decided to crawl mainly two forums on reddit related to bitcoin. And with the above custom function, a loop was formed. We decided to crawl mainly two forums on reddit related to bitcoin. And with the above custom function, a loop was formed. Eventually aggregated into a function that crawls all messages.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">findAllData</span><span class="p">(</span><span class="n">keywords</span><span class="p">):</span>
    <span class="n">browser</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">Chrome</span><span class="p">(</span><span class="s2">&quot;chromedriver.exe&quot;</span><span class="p">)</span>
    <span class="n">browser</span><span class="o">.</span><span class="n">implicitly_wait</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="c1"># url = &quot;https://www.quora.com/&quot;</span>
    <span class="c1"># browser.get(url)</span>
    <span class="c1"># time.sleep(3)</span>
    <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;data/&quot;</span> <span class="o">+</span> <span class="n">keyword</span> <span class="o">+</span> <span class="s2">&quot;.txt&quot;</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="s2">&quot;data/&quot;</span> <span class="o">+</span> <span class="n">keyword</span> <span class="o">+</span> <span class="s2">&quot;.txt&quot;</span><span class="p">)</span>
        <span class="n">search_url</span> <span class="o">=</span> <span class="s2">&quot;https://old.reddit.com/r/CryptoCurrency/search/?q=&quot;</span> <span class="o">+</span> <span class="n">keyword</span> <span class="o">+</span> <span class="s2">&quot;&amp;sort=top&amp;t=year&quot;</span>
        <span class="n">txt_list</span><span class="p">,</span> <span class="n">url_list</span><span class="p">,</span> <span class="n">time_list</span><span class="p">,</span> <span class="n">res_url</span> <span class="o">=</span> <span class="n">getPageData</span><span class="p">(</span><span class="n">browser</span><span class="p">,</span> <span class="n">search_url</span><span class="p">)</span>
        <span class="n">getPageComments</span><span class="p">(</span><span class="n">browser</span><span class="p">,</span> <span class="n">keyword</span><span class="p">,</span> <span class="n">txt_list</span><span class="p">,</span> <span class="n">url_list</span><span class="p">,</span> <span class="n">time_list</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">res_url</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">txt_list</span><span class="p">,</span> <span class="n">url_list</span><span class="p">,</span> <span class="n">time_list</span><span class="p">,</span> <span class="n">res_url</span> <span class="o">=</span> <span class="n">getPageData</span><span class="p">(</span><span class="n">browser</span><span class="p">,</span> <span class="n">res_url</span><span class="p">)</span>
            <span class="n">browser</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">browser</span><span class="o">.</span><span class="n">switch_to</span><span class="o">.</span><span class="n">window</span><span class="p">(</span><span class="n">browser</span><span class="o">.</span><span class="n">window_handles</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">getPageComments</span><span class="p">(</span><span class="n">browser</span><span class="p">,</span> <span class="n">keyword</span><span class="p">,</span> <span class="n">txt_list</span><span class="p">,</span> <span class="n">url_list</span><span class="p">,</span> <span class="n">time_list</span><span class="p">)</span>
            <span class="n">browser</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="n">browser</span><span class="o">.</span><span class="n">switch_to</span><span class="o">.</span><span class="n">window</span><span class="p">(</span><span class="n">browser</span><span class="o">.</span><span class="n">window_handles</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="c1"># time.sleep(3)</span>
            <span class="c1"># break</span>
    <span class="n">browser</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div>

<h3>Bitcointalk</h3>
<p>Bitcointalk.org is a forum where bitcoin followers are actively posting their discussions 
around various topics like bitcoin trading and technical development. To align with the timeline
of our project, we scrape the threads under the 'Bitcoin Discussion' section of the website for the last 30 days.</p>
<p>However, the threads all contain quotes from before. We thus decide to filter out all the threads we do not need,
and see if the term frequency might give a more accurate and appropriate result. </p>
<p>The web scraping includes both selenium and beautifulsoup, since this makes it easier to locate the posts.
But one limit is that during the craping, the new discussions will not be able to be captured at the time and they
might also change the order of the discussion topics, which could result in omission or repetition. We hope that this
would be resolved during data cleaning.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Use number of replies to calculate the total pages of posts (easier to go to next page).</span>
    <span class="c1"># Rather than going through all the pages, displaying all discussions is also an explicit way. </span>
    <span class="c1"># But the website is not responding well for some discussion topics</span>
        <span class="n">num_of_replies</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span><span class="s1">&#39;/html/body/div[2]/div[2]/table/tbody/tr[</span><span class="si">{}</span><span class="s1">]/td[5]&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">order</span><span class="p">))</span>
        <span class="n">pages</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num_of_replies</span><span class="o">.</span><span class="n">text</span><span class="p">)</span> <span class="o">/</span> <span class="mi">20</span><span class="p">)</span> 

    <span class="c1"># Choose a Discussion Topic</span>
        <span class="n">open_discussion</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span><span class="s1">&#39;/html/body/div[2]/div[2]/table/tbody/tr[</span><span class="si">{}</span><span class="s1">]/td[3]/span/a&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">order</span><span class="p">))</span>
        <span class="k">if</span> <span class="s1">&#39;Bitcoin puzzle transaction ~32 BTC prize to who solves it&#39;</span> <span class="ow">in</span> <span class="n">open_discussion</span><span class="o">.</span><span class="n">text</span><span class="p">:</span> <span class="c1"># the discussion under this topic contains too many threads and is irrelevant to our project.</span>
            <span class="k">continue</span>
        <span class="n">open_discussion</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

    <span class="c1"># Extract Posts (easier to locate using beautifulsoup)</span>
        <span class="n">searchweb</span> <span class="o">=</span> <span class="n">rq</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">browser</span><span class="o">.</span><span class="n">current_url</span><span class="p">))</span><span class="o">.</span><span class="n">text</span> 
        <span class="n">soup</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">searchweb</span><span class="p">)</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;td&#39;</span><span class="p">,</span><span class="s1">&#39;td_headerandpost&#39;</span><span class="p">)</span> 
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
            <span class="n">postlist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span>

    <span class="c1"># Go Through All the Pages</span>
        <span class="k">if</span> <span class="n">pages</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">pages</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
                <span class="n">All_link</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_link_text</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">page</span><span class="p">))</span>
                <span class="n">All_link</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">searchweb</span> <span class="o">=</span> <span class="n">rq</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">browser</span><span class="o">.</span><span class="n">current_url</span><span class="p">))</span><span class="o">.</span><span class="n">text</span> 
                <span class="n">soup</span> <span class="o">=</span> <span class="n">bs</span><span class="p">(</span><span class="n">searchweb</span><span class="p">)</span>
                <span class="n">text</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">&#39;td&#39;</span><span class="p">,</span><span class="s1">&#39;td_headerandpost&#39;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">text</span><span class="p">:</span>
                    <span class="n">postlist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">get_text</span><span class="p">())</span>

    <span class="c1"># Return to the discussion list page.</span>
        <span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</code></pre></div>

<h3>Twitter</h3>
<p>We are using twitter APi to access text data on twitter. We decide to obtain tweets created since 2022-02-16, with the keyword 'bitcoin', simple retweets not included.
Also, as required, we only choose the tweets in English.</p>
<div class="highlight"><pre><span></span><code><span class="n">client</span> <span class="o">=</span> <span class="n">tweepy</span><span class="o">.</span><span class="n">Client</span><span class="p">(</span><span class="n">bearer_token</span> <span class="o">=</span> <span class="n">bearer_token</span><span class="p">)</span>
<span class="n">query</span> <span class="o">=</span> <span class="s1">&#39;bitcoin -is:retweet lang:en&#39;</span>
<span class="n">tweets</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">search_all_tweets</span><span class="p">(</span><span class="n">query</span> <span class="o">=</span> <span class="n">query</span><span class="p">,</span><span class="n">max_results</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="n">tweet_fields</span> <span class="o">=</span><span class="p">[</span><span class="s1">&#39;created_at&#39;</span><span class="p">],</span> <span class="n">start_time</span> <span class="o">=</span> <span class="s1">&#39;2022-02-16T00:00:01Z&#39;</span><span class="p">)</span>
</code></pre></div>

<h3>Crypto News</h3>
<p>Since the news at Yahoo Finance covers only the latest news dating back to only 7 days ago, I think this time range is too short and some other earlier news need to be included as well. Under Cryptonews - News - Bitcoin News (https://cryptonews.com/news/bitcoin-news/), a section called 'All News' collected Bitcoin news initially shows 16 news. A button below called 'Load more news...' need to be clicked to show 8 more news. In this case, considering that sometimes the click fails, I looped the try-except click function for 60 times to get enough news dating back to February 9, 2022. </p>
<div class="highlight"><pre><span></span><code><span class="n">cryptonews_path</span> <span class="o">=</span> <span class="s1">&#39;https://cryptonews.com/news/bitcoin-news/&#39;</span>
<span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cryptonews_path</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">60</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>  
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
        <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_id</span><span class="p">(</span><span class="s1">&#39;load_more&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">-</span> <span class="mi">1</span>
</code></pre></div>

<p>After getting enough news we want, I made a loop to scrape the headline, content, and the time of the news. All these information of one single news are stored in a dictionary. This dictionary is then appended to a list of dictionaries. </p>
<div class="highlight"><pre><span></span><code><span class="n">news_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">xpath_list</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;load_more_target&quot;]/div[position()&gt;=1]/article/div/div[2]/a&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">xpath_list</span><span class="p">)):</span>
    <span class="n">link</span> <span class="o">=</span> <span class="n">xpath_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">get_attribute</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)</span>
    <span class="n">browser_news</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
    <span class="n">news</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;headline&#39;</span><span class="p">:</span> <span class="n">browser_news</span><span class="o">.</span><span class="n">find_element_by_css_selector</span><span class="p">(</span><span class="s1">&#39;h1.mb-40&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> 
           <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">browser_news</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span><span class="s1">&#39;/html/body/main/div[2]/div[2]/div[2]/div[2]&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> 
           <span class="s1">&#39;time&#39;</span><span class="p">:</span> <span class="n">browser_news</span><span class="o">.</span><span class="n">find_element_by_class_name</span><span class="p">(</span><span class="s1">&#39;fs-12&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;·&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]}</span>
    <span class="n">news_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">news</span><span class="p">)</span>
</code></pre></div>

<p>A copy of the scrapped data is then made and then formatted into a .csv file, source of these news is labelled as "Cryptonews" to enable future identification.  </p>
<h3>Cryptocurrency News at Yahoo Finance</h3>
<p>Under the News section on Yahoo Finance, we specifically focused on those under tab cryptocurrencies news. The initial website shows only 20 latest cryptocurrencies and bitcoin related news. To get a full record of all those news, we need to scroll down to the bottom of the web page and let the page to auto-load. Since a total of 150 news is expected, I made a scroll-to-bottom loop for 15 times to get the full page. </p>
<div class="highlight"><pre><span></span><code><span class="n">yahoo_path</span> <span class="o">=</span> <span class="s1">&#39;https://finance.yahoo.com/topic/crypto/&#39;</span>
<span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">yahoo_path</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">15</span><span class="p">):</span>
    <span class="c1"># Scroll down to bottom</span>
    <span class="n">browser</span><span class="o">.</span><span class="n">execute_script</span><span class="p">(</span><span class="s2">&quot;window.scrollTo(0, 1000000);&quot;</span><span class="p">)</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>

<p>After loading all the data, I developed a loop to click into each headline to extract the headline, content and time of the news. Each news with these three attributes are stored in a dictionary and then appended to a list containing all news dictionaries. Something worth noticing is that some news have button 'Story Continues', which need to be clicked for all content to be shown. In this case, a try-except command is included in the loop to ensure full content of a news is shown. </p>
<div class="highlight"><pre><span></span><code><span class="n">news_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">xpath_list</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;Fin-Stream&quot;]/ul/li[position()&gt;=1]/div/div/div[2]/h3/a&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">xpath_list</span><span class="p">)):</span>
    <span class="n">link</span> <span class="o">=</span> <span class="n">xpath_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">get_attribute</span><span class="p">(</span><span class="s1">&#39;href&#39;</span><span class="p">)</span>
    <span class="n">browser_news</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link</span><span class="p">)</span> 
    <span class="k">try</span><span class="p">:</span>
        <span class="n">browser_news</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span><span class="s2">&quot;//button[contains(., &#39;Story continues&#39;)]&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="n">news</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;headline&#39;</span><span class="p">:</span> <span class="n">browser_news</span><span class="o">.</span><span class="n">find_element_by_class_name</span><span class="p">(</span><span class="s1">&#39;caas-title-wrapper&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> 
           <span class="s1">&#39;content&#39;</span><span class="p">:</span> <span class="n">browser_news</span><span class="o">.</span><span class="n">find_element_by_class_name</span><span class="p">(</span><span class="s1">&#39;caas-body&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> 
           <span class="s1">&#39;time&#39;</span><span class="p">:</span> <span class="p">(</span><span class="n">browser_news</span><span class="o">.</span><span class="n">find_element_by_class_name</span><span class="p">(</span><span class="s1">&#39;caas-attr-time-style&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;·&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]}</span>
    <span class="n">news_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">news</span><span class="p">)</span>
</code></pre></div>

<p>Then I made a copy of the scraped data and output it into a .csv form. I labeled the source as "Yahoo Finance" to distinguish news from different sources if we further merge all data together. </p>
<div class="highlight"><pre><span></span><code><span class="n">yahoo_news_150</span> <span class="o">=</span> <span class="n">news_list</span>
<span class="n">headline</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">content</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">time_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">source</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">news</span> <span class="ow">in</span> <span class="n">yahoo_news_150</span><span class="p">:</span>
    <span class="n">headline</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">news</span><span class="p">[</span><span class="s1">&#39;headline&#39;</span><span class="p">])</span>
    <span class="n">content</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">news</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">])</span>
    <span class="n">time_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">news</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">])</span>
    <span class="n">source</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;Yahoo Finance&#39;</span><span class="p">)</span>
<span class="n">news_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;Headline&#39;</span><span class="p">:</span> <span class="n">headline</span><span class="p">,</span> <span class="s1">&#39;Content&#39;</span><span class="p">:</span> <span class="n">content</span><span class="p">,</span> <span class="s1">&#39;Time&#39;</span><span class="p">:</span> <span class="n">time_list</span><span class="p">,</span> <span class="s1">&#39;Source&#39;</span><span class="p">:</span> <span class="n">source</span><span class="p">}</span> <span class="p">)</span>
<span class="n">news_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">current_path</span> <span class="o">+</span> <span class="s1">&#39;/Yahoo Finance cryptonews.csv&#39;</span><span class="p">)</span>
</code></pre></div>

<h3>Bitcoin price data from coinmarketcap</h3>
<p>The initial page only shows 60 days price. To access more comments, we need to click the \textbf{Show more} button to load more each time. We decide to load all the comments within the desired timeframe on the website before scrapping them. We are not able to come up with a smart way to have the computer to stop itself automatically when it reaches a specific date so we just go with the stupid one instead. The stupid way is to write a loop to click the button 11 times, then we manually check the date of the last price data. This process would be repeated until we have all the data we wanted.</p>
<div class="highlight"><pre><span></span><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;https://coinmarketcap.com/currencies/bitcoin/historical-data/&#39;</span>
<span class="n">browser</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">11</span><span class="p">):</span>
    <span class="n">element</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_element_by_xpath</span><span class="p">(</span> <span class="s1">&#39;//*[@id=&quot;__next&quot;]/div[1]/div[1]/div[2]/div/div[3]/div/div/p[1]/button&#39;</span><span class="p">)</span>                                          
    <span class="n">element</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>

<p>After finish loading all the price data, we scrap the date, open price, close price, highest price, lowest data, volume and Market Cap of the price date and save them into a dataframe.</p>
<div class="highlight"><pre><span></span><code><span class="n">recorded_date</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;__next&quot;]/div[1]/div[1]/div[2]/div/div[3]/div/div/div[2]/table/tbody/tr[position()&gt;=1]/td[1]&#39;</span><span class="p">)</span>
<span class="n">rec_date</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">recorded_date</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rec_date</span>

<span class="n">open_price</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;__next&quot;]/div[1]/div[1]/div[2]/div/div[3]/div/div/div[2]/table/tbody/tr[position()&gt;=1]/td[2]&#39;</span><span class="p">)</span>
<span class="n">open_price</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span><span class="n">open_price</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Open&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">open_price</span>

<span class="n">high</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;__next&quot;]/div[1]/div[1]/div[2]/div/div[3]/div/div/div[2]/table/tbody/tr[position()&gt;=1]/td[3]&#39;</span><span class="p">)</span>
<span class="n">high</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span><span class="n">high</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;High&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">high</span>

<span class="n">low</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;__next&quot;]/div[1]/div[1]/div[2]/div/div[3]/div/div/div[2]/table/tbody/tr[position()&gt;=1]/td[4]&#39;</span><span class="p">)</span>
<span class="n">low</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span><span class="n">low</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Low&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">low</span>

<span class="n">close</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;__next&quot;]/div[1]/div[1]/div[2]/div/div[3]/div/div/div[2]/table/tbody/tr[position()&gt;=1]/td[5]&#39;</span><span class="p">)</span>
<span class="n">close</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span><span class="n">close</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Close&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">close</span>

<span class="n">volume</span> <span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;__next&quot;]/div[1]/div[1]/div[2]/div/div[3]/div/div/div[2]/table/tbody/tr[position()&gt;=1]/td[6]&#39;</span><span class="p">)</span>
<span class="n">volume</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span><span class="n">volume</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Volume&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">volume</span>


<span class="n">Market_Cap</span><span class="o">=</span> <span class="n">browser</span><span class="o">.</span><span class="n">find_elements_by_xpath</span><span class="p">(</span><span class="s1">&#39;//*[@id=&quot;__next&quot;]/div[1]/div[1]/div[2]/div/div[3]/div/div/div[2]/table/tbody/tr[position()&gt;=1]/td[7]&#39;</span><span class="p">)</span>
<span class="n">Market_Cap</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">text</span><span class="p">,</span><span class="n">Market_Cap</span><span class="p">))</span>
<span class="n">df</span><span class="p">[</span><span class="s1">&#39;Market Cap&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Market_Cap</span>
<span class="k">return</span> <span class="n">df</span>
</code></pre></div>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2022-03-21T12:25:00+08:00">Mon 21 March 2022</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/categories.html#progress-report-ref">Progress Report</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/MFIN7036-student-blog-2022-02" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>