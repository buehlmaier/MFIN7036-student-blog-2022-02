<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="MFIN7036 Students" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Progress Report, " />

<meta property="og:title" content="Preprocessing (Group NLP_0) "/>
<meta property="og:url" content="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/preprocessing-group-nlp_0.html" />
<meta property="og:description" content="By Group &#34;NLP_0&#34; This blog describes the problems and adjustments we made during preprocessing. From Annual Reports to Nouns List 1.Ideas and Goals After collecting the text of the annual reports of all U.S. public companies from the SEC Edgar Website, the raw text data needs to …" />
<meta property="og:site_name" content="MFIN7036 Student Blog" />
<meta property="og:article:author" content="MFIN7036 Students" />
<meta property="og:article:published_time" content="2022-03-29T01:10:00+08:00" />
<meta name="twitter:title" content="Preprocessing (Group NLP_0) ">
<meta name="twitter:description" content="By Group &#34;NLP_0&#34; This blog describes the problems and adjustments we made during preprocessing. From Annual Reports to Nouns List 1.Ideas and Goals After collecting the text of the annual reports of all U.S. public companies from the SEC Edgar Website, the raw text data needs to …">

        <title>Preprocessing (Group NLP_0)  · MFIN7036 Student Blog
</title>
        <link href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="MFIN7036 Student Blog - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/"><span class=site-name>MFIN7036 Student Blog</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/MFIN7036-student-blog-2022-02
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/preprocessing-group-nlp_0.html">
                Preprocessing (Group NLP_0)
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By Group "NLP_0"</p>
<p>This blog describes the problems and adjustments we made during preprocessing.</p>
<h2>From Annual Reports to Nouns List</h2>
<h4>1.Ideas and Goals</h4>
<p>After collecting the text of the annual reports of all U.S. public companies from the SEC Edgar Website, the raw text data needs to be processed. The purpose of this step is to transform the text in the "Item 1 business" section of the raw annual report text into a list of nouns that does not contain geographical and temporal nouns. The main packages used are spacy and nltk.</p>
<h4>2.Core Function : getn (cik,year)</h4>
<p>The function getn (cik,year), as the main function to achieve the result , has the following processing steps.</p>
<h5>(1) Automatically select the required text</h5>
<p>Only the "Item 1 Business" part of the text needs to be analyzed, some of the text material has subsequent item 1a and item 1b parts that do not need to be analyzed. This is achieved by the following code.</p>
<ul>
<li>Slice and dice the text into lists by sentence, converting all characters to lowercase</li>
<li>Iterate through the sentence until the string 'item 1a' is found in the sentence, and if 'item 1a' is not found, look for the string 'item 1b' (taking into account that Some text does not have 1a but only part 1b</li>
<li>Once the string 'item 1a' is found, the ordinal number of this sentence is returned and all previous texts are selected for analysis, and if neither keyword is found, the full text is selected.</li>
</ul>
<div class="highlight"><pre><span></span><code><span class="err">text = f.readlines()</span>
<span class="err">for i in text:</span>
<span class="err">    #i = str(i)</span>
<span class="err">    if &#39;item 1a&#39; in i.lower():</span>
<span class="err">        a_index = text.index(i)</span>
<span class="err">        bus_list = text[:a_index]</span>
<span class="err">        print(&#39;find item 1a&#39;)</span>
<span class="err">        break</span>
<span class="err">    elif &#39;item 1b&#39; in i.lower():</span>
<span class="err">        b_index = text.index(i)</span>
<span class="err">        bus_list = text[:b_index]</span>
<span class="err">        print(&#39;can not find item 1a find 1b&#39;)</span>
<span class="err">        break</span>
<span class="err">     else:</span>
<span class="err">        bus_list = text</span>
<span class="err">if bus_list == text:</span>
<span class="err">print(&#39;only have business&#39;)</span>
</code></pre></div>

<h5>(2) Identify the entities to be removed</h5>
<p>Use the spacy package to extract all entities in the text and store the location entities and time entities labeled 'GPE' and 'DATE' in drop_list.</p>
<div class="highlight"><pre><span></span><code><span class="err">drop_list = []</span>
<span class="err">doc = nlp(con_str)</span>
<span class="err">for word in list(doc.ents):  </span>
<span class="err">    #print(str(word), str(word.label_))</span>
<span class="err">    if str(word.label_) == &#39;GPE&#39; or str(word.label_) == &#39;DATE&#39;:</span>
<span class="err">        drop_list.append(str(word))</span>
</code></pre></div>

<h5>(3) Generate a list of target nouns</h5>
<p>Read the text, remove all the strings in drop_list by the replace method corresponding to the strings, and obtain the text that does not contain the time and place entities. Analyze each word, get the attributes of each word of the text by word.pos_, keep the words with the attributes PROPN and NOUN, and remove some of the nonsense characters observed by sampling check.</p>
<div class="highlight"><pre><span></span><code><span class="err">for word in list(doc_):</span>
<span class="err">    if (str(word.pos_) == &#39;PROPN&#39; or str(word.pos_) == &#39;NOUN&#39;) and str(word) != &#39;%&#39; and str(word) != &#39;10-Q&#39; and (&#39;(&#39; not in str(word)) and str(word) not in [&#39;one&#39;,&#39;two&#39;,&#39;three&#39;,&#39;four&#39;,&#39;five&#39;] and str(word) != &#39;ITEM&#39; and str(word) != &#39;BUSINESS&#39; and (&#39;www&#39; not in str(word)) :</span>
<span class="err">    n_list.append(str(word))</span>
</code></pre></div>

<h5>(4) Outputting a list of nouns</h5>
<p>An annual report outputs a list of nouns.</p>
<p>3.Overall processing logic</p>
<p>Each company corresponds to a cik folder in which the text of annual reports from 2010-2021 is stored according to a uniform format.</p>
<p>Through cik_list = os.listdir(path) to generate a list of cik corresponding to the folder name under the path, traverse the folder to extract the contents of each annual report to getn (cik,year) function, the output noun list.</p>
<div class="highlight"><pre><span></span><code><span class="s s-Atom">ik_list</span> <span class="o">=</span> <span class="s s-Atom">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="s s-Atom">path</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="s s-Atom">cik_list</span><span class="p">))</span>
<span class="s s-Atom">#cik_list</span> <span class="o">=</span> <span class="s s-Atom">cik_list</span><span class="p">[</span><span class="s s-Atom">:</span><span class="mi">5</span><span class="p">]</span>
<span class="s s-Atom">num</span> <span class="o">=</span> <span class="mi">0</span>
<span class="s s-Atom">for</span> <span class="s s-Atom">a</span> <span class="s s-Atom">in</span> <span class="s s-Atom">cik_list:</span>
    <span class="s s-Atom">cik_dic</span> <span class="s s-Atom">=</span><span class="p">{}</span>
    <span class="s s-Atom">mda</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="s s-Atom">business</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="s s-Atom">txt_path</span> <span class="o">=</span> <span class="s s-Atom">path</span> <span class="s s-Atom">+</span><span class="err">&quot;</span><span class="s s-Atom">\\</span><span class="s2">&quot;+a</span>
<span class="s2">    #print(txt_path)</span>
<span class="s2">    if len(os.listdir(txt_path)) == 0:  </span>
<span class="s2">         print(a +&quot;</span><span class="s s-Atom">folder</span> <span class="o">is</span> <span class="s s-Atom">empty</span><span class="s2">&quot;)</span>
<span class="s2">    else: </span>
<span class="s2">         print(a +&quot;</span><span class="s s-Atom">folder</span> <span class="o">is</span> <span class="o">not</span> <span class="s s-Atom">empty</span><span class="err">&quot;</span><span class="p">)</span>
         <span class="s s-Atom">txt_list</span> <span class="o">=</span> <span class="s s-Atom">os</span><span class="p">.</span><span class="nf">listdir</span><span class="p">(</span><span class="s s-Atom">txt_path</span><span class="p">)</span>
         <span class="s s-Atom">for</span> <span class="s s-Atom">b</span> <span class="s s-Atom">in</span> <span class="s s-Atom">txt_list:</span>
             <span class="s s-Atom">cik_value</span> <span class="o">=</span> <span class="s s-Atom">b</span><span class="p">[</span><span class="mi">5</span><span class="s s-Atom">:</span><span class="mi">15</span><span class="p">]</span>
             <span class="s s-Atom">year_value</span> <span class="o">=</span> <span class="s s-Atom">b</span><span class="p">[</span><span class="mi">16</span><span class="s s-Atom">:</span><span class="mi">20</span><span class="p">]</span>
             <span class="s s-Atom">type_value</span> <span class="o">=</span> <span class="s s-Atom">b</span><span class="p">[</span><span class="mi">25</span><span class="s s-Atom">:</span><span class="p">][:-</span><span class="mi">4</span><span class="p">]</span>
             <span class="s s-Atom">#</span><span class="nf">print</span><span class="p">(</span><span class="s s-Atom">year_value</span><span class="p">)</span>

             <span class="s s-Atom">if</span> <span class="s s-Atom">type_value</span> <span class="o">==</span> <span class="s s-Atom">&#39;business&#39;:</span>

                 <span class="s s-Atom">if</span> <span class="s s-Atom">year_value</span> <span class="o">==</span> <span class="s s-Atom">&#39;2010&#39;:</span>
                     <span class="s s-Atom">list_b</span> <span class="o">=</span> <span class="nf">getn</span><span class="p">(</span><span class="s s-Atom">cik_value</span><span class="p">,</span> <span class="s s-Atom">year_value</span><span class="p">)</span>
                     <span class="s s-Atom">n_2010</span><span class="p">[</span><span class="s s-Atom">cik_value</span><span class="p">]</span> <span class="o">=</span> <span class="s s-Atom">list_b</span>
                 <span class="s s-Atom">if</span> <span class="s s-Atom">year_value</span> <span class="o">==</span> <span class="s s-Atom">&#39;2011&#39;:</span>
                     <span class="s s-Atom">list_b</span> <span class="o">=</span> <span class="nf">getn</span><span class="p">(</span><span class="s s-Atom">cik_value</span><span class="p">,</span> <span class="s s-Atom">year_value</span><span class="p">)</span>
                     <span class="s s-Atom">n_2011</span><span class="p">[</span><span class="s s-Atom">cik_value</span><span class="p">]</span> <span class="o">=</span> <span class="s s-Atom">list_b</span>  
                 <span class="s s-Atom">if</span> <span class="s s-Atom">year_value</span> <span class="o">==</span> <span class="s s-Atom">&#39;2012&#39;:</span>
                     <span class="s s-Atom">list_b</span> <span class="o">=</span> <span class="nf">getn</span><span class="p">(</span><span class="s s-Atom">cik_value</span><span class="p">,</span> <span class="s s-Atom">year_value</span><span class="p">)</span>
                     <span class="s s-Atom">n_2012</span><span class="p">[</span><span class="s s-Atom">cik_value</span><span class="p">]</span> <span class="o">=</span> <span class="s s-Atom">list_b</span>
</code></pre></div>

<h4>4.Result format and storage method</h4>
<p>Store the list of nouns in the form of dictionary, key value is cik, value is the list of nouns, each year corresponds to a dictionary. Store the dictionaries as pickle files.</p>
<div class="highlight"><pre><span></span><code><span class="n">name_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">&#39;n_2010&#39;,&#39;n_2011&#39;,&#39;n_2012&#39;,&#39;n_2013&#39;,&#39;n_2014&#39;,&#39;n_2015&#39;,&#39;n_2016&#39;,&#39;n_2017&#39;,&#39;n_2018&#39;,&#39;n_2019&#39;,&#39;n_2020&#39;,&#39;n_2021&#39;</span><span class="o">]</span><span class="w"></span>
<span class="n">res_list</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">n_2010,n_2011,n_2012,n_2013,n_2014,n_2015,n_2016,n_2017,n_2018,n_2019,n_2020,n_2021</span><span class="o">]</span><span class="w"></span>

<span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">name_list</span><span class="p">))</span><span class="err">:</span><span class="w"></span>
<span class="w">    </span><span class="k">with</span><span class="w"> </span><span class="k">open</span><span class="p">(</span><span class="n">name_list</span><span class="o">[</span><span class="n">i</span><span class="o">]+</span><span class="s1">&#39;.txt&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;wb&#39;</span><span class="p">)</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="k">file</span><span class="err">:</span><span class="w"></span>
<span class="w">        </span><span class="n">pickle</span><span class="p">.</span><span class="k">dump</span><span class="p">(</span><span class="n">res_list</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="k">file</span><span class="p">)</span><span class="w">  </span>
</code></pre></div>

<p>Dictionary format：</p>
<div class="highlight"><pre><span></span><code><span class="err">{&#39;0000001750&#39;: [&#39;General&#39;, &#39;AAR&#39;, &#39;CORP&#39;, &#39;.&#39;, &#39;subsidiaries&#39;, &#39;herein&#39;, &#39;AAR&#39;, &#39;Company&#39;, &#39;context&#39;, &#39;AAR&#39;, &#39;provider&#39;, &#39;products&#39;, &#39;services&#39;, &#39;aviation&#39;, &#39;government&#39;, &#39;defense&#39;, &#39;markets&#39;, &#39;plan&#39;, &#39;strategy&#39;, &#39;class&#39;, &#39;aviation&#39;, &#39;services&#39;, &#39;business&#39;, &#39;segments&#39;, &#39;Aviation&#39;, &#39;Services&#39;, &#39;Expeditionary&#39;, ...],&#39;0000001800&#39;:[&#39;GENERAL&#39;, &#39;DEVELOPMENT&#39;, &#39;Laboratories&#39;, &#39;corporation&#39;, &#39;business&#39;, &#39;discovery&#39;, &#39;development&#39;, &#39;manufacture&#39;, &#39;sale&#39;, &#39;line&#39;, &#39;health&#39;, &#39;care&#39;, &#39;products&#39;,...]...}</span>
</code></pre></div>

<h2>Turning Nouns List into BoW Matrix</h2>
<p>As the first stage of data cleaning is mostly about overcoming the volume and disarray in the raw data, we find it necessary to continue refining nouns list during vectorization.</p>
<dl>
<dt>Here is a random check of nouns from initial stage. Some problems that will affect later analyses are</dt>
<dd>
<ol>
<li>duplicate words: as we will create a binary BoW matrix, how many times a word appears is not useful</li>
<li>inconsistent formats: all capital, initial capital, capital followed by numbers were used to identify Nouns and Proper Nouns, but formats do not convey extra information for later analyses</li>
<li>weird symbols(likely residual html entities): they simply add noises</li>
<li>split words and repetition of section title "Item 1 Business": they serve a signposting role, but we decide to discard them to focus on actual contents</li>
</ol>
</dd>
</dl>
<p><img alt="Image showing nouns" src="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/images/NLP_0-random-check-nouns.png"></p>
<p>So we define a customized tokenizer as a parameter in <code>sklearn.feature_extraction.text.CountVectorizer</code>,
along with restrictions on across-document word frequency (<code>max_df</code> and <code>min_df</code>) to get BoW matrix.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># clean nouns and create BoW matrix</span>
    <span class="k">def</span> <span class="nf">custom_tokenizer</span><span class="p">(</span><span class="n">doc</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
        <span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
        <span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>
        <span class="kn">import</span> <span class="nn">enchant</span>
        <span class="n">stop_words</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
        <span class="n">stop_words</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s1">&#39;item&#39;</span><span class="p">,</span> <span class="s1">&#39;general&#39;</span><span class="p">,</span> <span class="s1">&#39;business&#39;</span><span class="p">,</span> <span class="s1">&#39;overview&#39;</span><span class="p">])</span>
        <span class="n">wnl</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
        <span class="n">en_dict</span> <span class="o">=</span> <span class="n">enchant</span><span class="o">.</span><span class="n">Dict</span><span class="p">(</span><span class="s1">&#39;en_US&#39;</span><span class="p">)</span>

        <span class="n">tokens</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">t</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop_words</span><span class="p">]</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">t</span><span class="o">.</span><span class="n">isnumeric</span><span class="p">()]</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">t</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()]</span>
        <span class="n">tokens_pn</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">isupper</span><span class="p">())</span> <span class="ow">or</span> <span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">istitle</span><span class="p">())]</span>
        <span class="n">tokens_cn</span> <span class="o">=</span> <span class="p">[</span><span class="n">wnl</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">pos</span><span class="o">=</span><span class="s1">&#39;n&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">if</span> <span class="n">en_dict</span><span class="o">.</span><span class="n">check</span><span class="p">(</span><span class="n">t</span><span class="p">)]</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">tokens_pn</span><span class="p">)</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">tokens_cn</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">tokens</span>

    <span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="n">custom_tokenizer</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.50</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span> <span class="c1">#unique words</span>
    <span class="n">word_matrix</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">ciks_doc</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span> <span class="c1">#should have shape(len(cik), len(word_list))</span>
    <span class="n">word_list</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Word matrix has shape: {word_matrix.shape}&quot;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Number of companies: {len(ciks)}, number of words: {len(word_list)}&#39;</span><span class="p">)</span>
</code></pre></div>

<p>First check if our word format problems have been addressed:</p>
<p><img alt="Image showing further cleaned nouns" src="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/images/NLP_0-further-cleaned-nouns.png"></p>
<p>This image shows that, on the surface, all words appear to be unique, consistently-formatted nouns (some very short words stand out, like "z", "ab", but they may come from proper nouns abbreviations, so we keep them).</p>
<p>Next we further check word quality by its meaningfulness. As the matrix consists of each company's product nouns, we can use this as a dictionary, and look up certain companies by its product/service keywords.
For example, we choose "software", "computer", and "program" to find CIKs of companies that broadly fit into internet, computer manufacturing, etc. businesses. We link CIKs to our Compustat company name list and industry classification variables to get details.</p>
<div class="highlight"><pre><span></span><code><span class="err"># check keywords: software, computer, program</span>
<span class="err">    for keyword in [&#39;software&#39;, &#39;computer&#39;, &#39;program&#39;]:</span>
<span class="err">        if keyword in word_list:</span>
<span class="err">            print(f&#39;{keyword} in word_list, index is {word_list.index(keyword)}&#39;)</span>
<span class="err">        else:</span>
<span class="err">            print(f&#39;{keyword} not in word_list.&#39;)</span>
<span class="err">    # software, computer are in word_list, index 3388, 746</span>
<span class="err">    mask = word_matrix[:, [3388, 746]] != 0</span>
<span class="err">    comp_ciks = pd.Series(ciks)[np.any(mask, axis=1)].tolist()</span>
<span class="err">    # load pre-compiled company name list for look-up</span>
<span class="err">    df = pd.read_csv(&#39;company_name_cik.csv&#39;)</span>
<span class="err">    df = df.dropna()</span>
<span class="err">    df = df.drop_duplicates()</span>
<span class="err">    df[[&#39;cik&#39;, &#39;sic&#39;, &#39;naics&#39;]] = df[[&#39;cik&#39;, &#39;sic&#39;, &#39;naics&#39;]].astype(&#39;int&#39;).astype(&#39;str&#39;)</span>
<span class="err">    df[&#39;cik&#39;] = df[&#39;cik&#39;].apply(lambda x: x.rjust(10, &#39;0&#39;))</span>
<span class="err">    print(df[df.cik.isin(comp_ciks)])</span>
</code></pre></div>

<p>Partial results are shown in this image:</p>
<p><img alt="Image showing software companies in result" src="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/images/NLP_0-partial-software-comps.png"></p>
<p>According to <a href="https://finance.yahoo.com/quote/WDDD/profile?p=WDDD">Yahoo Finance</a>, the third company, Worlds Inc., is in Technology sector, software-application industry, which dovetails our expectation; another company, ATRION Corp., is in Healthcare sector, medical instruments and suppliers industry (see corresponding page on <a href="https://finance.yahoo.com/quote/ATRI/profile?p=ATRI">Yahoo Finance</a>), which shows relatively weak link to our idea of technology firms. A further dive into the original 10-K text shows that ATRION is focused on developing medical devices, some of them are software-based. Also, the company itself is in the process of updating its own Enterprise Resource Planning and software systems. Overall, it seems fair to include ATRION as a technology firm. Other companies down the list also seem related to Internet, Technology and Software, albeit requiring some disambiguation, indicating that our company product dictionary is reasonably accurate. With this, we consider the matrix ready for later clustering and similarity calculation.</p>
<h2>Extract Competition Mentions from MD&amp;A Section, and Preserve Meaning</h2>
<p>As we intend to use management's discussion of competition as an alternative competition measure, we explicitly count competition words, i.e., "competition", "competitor", "compete", "competitive", and divide the count by MD&amp;A section length to increase comparability. However, this measure suffers from at least two problems: firstly, it is quite limited in range, as most are below 0.1; secondly, it assumes that competition intensity comes from repetition of the keyword 'competition', which potentially misses out adjectives describing competition intensity, e.g., 'significant competition', and the general context.</p>
<dl>
<dt>To improve on this measure, we add two elements:</dt>
<dd>
<ol>
<li>incorporate sentiment score of competition sentences using <code>nltk.sentiment.vader</code></li>
<li>incorporate synonyms for lemmatized "competition" words using <code>nltk.corpus.wordnet</code></li>
</ol>
</dd>
</dl>
<p>The codes used for these tasks are simple, and we only include a snippet here for the sake of being complete.</p>
<div class="highlight"><pre><span></span><code><span class="err"># para level</span>
<span class="err">   for para in doc_paras:</span>
<span class="err">       # sentence level</span>
<span class="err">       doc_sents = sent_tokenize(para)</span>
<span class="err">       # keep sentences that have compet_syns</span>
<span class="err">       for sent in doc_sents:</span>
<span class="err">           compet_words = [word for word in word_tokenize(sent)</span>
<span class="err">                           if wnl.lemmatize(word) in compet_syns]</span>
<span class="err">           # if mention compet, calculate sentence sentiment</span>
<span class="err">           if compet_words:</span>
<span class="err">               print(sent)</span>
<span class="err">               print(compet_words)</span>
<span class="err">               doc_mentions.extend(compet_words)</span>
<span class="err">               sentiment = sid.polarity_scores(sent)</span>
<span class="err">               print(sentiment)</span>
<span class="err">               doc_sentiments.append(sentiment[&#39;compound&#39;])</span>
<span class="err">               # compound score of 0 means the sentence is neutral</span>
<span class="err">   # append at doc level</span>
<span class="err">   compet_mentions.append(doc_mentions)</span>
<span class="err">   compet_sentiments.append(doc_sentiments)</span>
</code></pre></div>

<p>What we find quite interesting is the nuance after adding these steps, although they do not improve the data range and still capture limited meaning.</p>
<p>For the first step, we only keep the compound sentiment score, which is between -1 and 1, with 0 being completely neutral. The results are still mostly small numbers around 0, but positive scores prevail. This reveals that management's attitudes toward competition, or more precisely, assessments of competition mentioned in MD&amp;A, are not necessarily negative. In fact, in the majority of the years in our sample (2010 to 2021), sentences including companies' competition mentions are mostly scored to be positive. The graph shows nine years (2012 to 2020), and the shared y axis makes it easy to see that most data is above 0. This may show that management are slightly biased to make good impressions.</p>
<p><img alt="Image of sentiment scores in nine years" src="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/images/NLP_0-competition-sentiments.png"></p>
<p>For the second step, although we are able to expand search to more words (i.e., "rival", "contender", "vie"), the result seems to show that management strongly prefer to use "compet-" words. The following two plots show the vocabulary and its frequency from 2011 to 2021 for two randomly-chosen companies.</p>
<p><img alt="Image showing first frequency plot of competition" src="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/images/NLP_0-competition-FD1.png"> <img alt="Image showing second frequency plot of competition" src="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/images/NLP_0-competition-FD2.png"></p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2022-03-29T01:10:00+08:00">Tue 29 March 2022</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/categories.html#progress-report-ref">Progress Report</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/MFIN7036-student-blog-2022-02" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/MFIN7036-student-blog-2022-02/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>